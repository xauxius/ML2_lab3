{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "from utils import encode_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, model, game, value, player, parent, action):\n",
    "        self.model = model\n",
    "        self.game = game\n",
    "        self.value = value\n",
    "        self.player = player\n",
    "\n",
    "        self.parent = parent\n",
    "        self.action = action\n",
    "        self.childs = []\n",
    "\n",
    "        self.S = 0\n",
    "        self.N = 0\n",
    "        self.V = 0\n",
    "        self.P = []\n",
    "\n",
    "        self.evaluate()\n",
    "\n",
    "    def evaluate(self):\n",
    "        state = self.game.prepareBoardForPlayer(self.player)\n",
    "        encoded_state = encode_state(state)\n",
    "        self.P, self.V = self.model(np.array([encoded_state]))\n",
    "        self.P, self.V = np.array(self.P)[0], np.array(self.V)[0, 0]\n",
    "        \n",
    "    def expand(self):\n",
    "        actions = self.game.getPossibleActions()\n",
    "        for action in actions:\n",
    "            game = copy.deepcopy(self.game)\n",
    "            game.updateBoard(action, self.value)\n",
    "            child = Node(self.model, game, self.value * -1, self.player, self, action)\n",
    "            self.childs.append(child)\n",
    "            child.backpropogate(child.V)\n",
    "    \n",
    "    def backpropogate(self, value):\n",
    "        node = self\n",
    "        while node != None:\n",
    "            node.S += value\n",
    "            node.N += 1\n",
    "            node = node.parent\n",
    "\n",
    "    def select_child(self, C):\n",
    "        if len(self.childs) > 0:\n",
    "            UCBs = [child.UCB(C) for child in self.childs]\n",
    "            max_i = np.argmax(UCBs)\n",
    "            return self.childs[max_i]\n",
    "        else:\n",
    "            return None\n",
    "\n",
    "    def UCB(self, C):\n",
    "        l = self.S / self.N if self.N > 0 else 0\n",
    "        r = self.P[self.action] * C * np.sqrt(self.parent.N) / (1 + self.N)\n",
    "        return l + r\n",
    "    \n",
    "    def get_child_by_action(self, action):\n",
    "        for child in self.childs:\n",
    "            if child.action == action:\n",
    "                return child\n",
    "        return None\n",
    "\n",
    "class MCTS:\n",
    "    def __init__(self, model, C, thinking_amount, stop_mode = \"time\"):\n",
    "        self.model = model\n",
    "        self.C = C\n",
    "        self.thinking_amount = thinking_amount\n",
    "        self.stop_mode = stop_mode\n",
    "\n",
    "    def think(self, game, value):\n",
    "        root = Node(self.model, copy.deepcopy(game), value, value, None, None)\n",
    "        self.start_time = time.time()\n",
    "        self.expanded = 0\n",
    "        while self.should_think():\n",
    "            node = self.select(root)\n",
    "            node.expand()\n",
    "            self.expanded += 1\n",
    "        \n",
    "        # print(f\"expanded: {self.expanded}\")\n",
    "        p = []\n",
    "        # all_n = sum([child.N for child in root.childs])\n",
    "        for action in range(7):\n",
    "            child = root.get_child_by_action(action)\n",
    "            p_val = 0 if child == None else child.N / root.N# all_n\n",
    "            p.append(p_val)\n",
    "        return p\n",
    "    \n",
    "    def should_think(self):\n",
    "        if self.stop_mode == \"time\":\n",
    "            return time.time() - self.start_time < self.thinking_amount\n",
    "        else:\n",
    "            return self.expanded < self.thinking_amount\n",
    "\n",
    "    def select(self, node):\n",
    "        selected = node.select_child(self.C)\n",
    "        while selected != None:\n",
    "            node = selected\n",
    "            selected = node.select_child(self.C)\n",
    "        return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from game import gamerules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MCTSPlayer(gamerules.Player):\n",
    "    def __init__(self, name, mcts):\n",
    "        super().__init__(name)\n",
    "        self.mcts = mcts\n",
    "    \n",
    "    def getAction(self, board, value):\n",
    "        actions = self.mcts.think(board, value)\n",
    "        action = np.argmax(actions)\n",
    "        return action\n",
    "\n",
    "    def newGame(self, new_opponent):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import play_game, test_games\n",
    "from classes.player import RNGPlayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mcts = MCTS(0.8, 1)\n",
    "# p1 = MCTSPlayer(\"Custom\", mcts)\n",
    "# p2 = RNGPlayer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_games(p1, p2, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_2 (InputLayer)           [(None, 6, 7, 3)]    0           []                               \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)              (None, 6, 7, 32)     896         ['input_2[0][0]']                \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)              (None, 6, 7, 64)     18496       ['conv2d_3[0][0]']               \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)              (None, 6, 7, 64)     36928       ['conv2d_4[0][0]']               \n",
      "                                                                                                  \n",
      " flatten_1 (Flatten)            (None, 2688)         0           ['conv2d_5[0][0]']               \n",
      "                                                                                                  \n",
      " dense_2 (Dense)                (None, 128)          344192      ['flatten_1[0][0]']              \n",
      "                                                                                                  \n",
      " dense_3 (Dense)                (None, 64)           8256        ['dense_2[0][0]']                \n",
      "                                                                                                  \n",
      " policy (Dense)                 (None, 7)            455         ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      " value (Dense)                  (None, 1)            65          ['dense_3[0][0]']                \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 409,288\n",
      "Trainable params: 409,288\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_network():\n",
    "    input = keras.Input((6, 7, 3))\n",
    "    x = keras.layers.Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(input)\n",
    "    x = keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = keras.layers.Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\n",
    "    x = keras.layers.Flatten()(x)\n",
    "    x = keras.layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = keras.layers.Dense(64, activation=\"relu\")(x)\n",
    "\n",
    "    policy = keras.layers.Dense(7, activation=\"softmax\", name=\"policy\")(x)\n",
    "    value = keras.layers.Dense(1, name=\"value\")(x)\n",
    "    model = keras.Model(inputs=input, outputs=[policy, value])\n",
    "    return model\n",
    "\n",
    "model = build_network()\n",
    "\n",
    "model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss={\n",
    "        \"policy\": \"categorical_crossentropy\",\n",
    "        \"value\": \"mean_squared_error\"\n",
    "    },\n",
    "    metrics = {\n",
    "        \"policy\": \"accuracy\",\n",
    "        \"value\": \"mse\"\n",
    "    }\n",
    ")\n",
    "\n",
    "model.summary()\n",
    "model.save(\"models/model_init.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(\n",
      "[[0.15262103 0.1334935  0.12522776 0.15412737 0.1386852  0.14764065\n",
      "  0.14820446]], shape=(1, 7), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "board = gamerules.Board()\n",
    "encoded_state = encode_state(board.board)\n",
    "# expanded = np.expand_dims(encoded_state, axis=0)\n",
    "pol, val = model(np.array([encoded_state]))\n",
    "print(pol)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.15262103 0.1334935  0.12522776 0.15412737 0.1386852  0.14764065\n",
      " 0.14820446]\n",
      "-0.059420027\n"
     ]
    }
   ],
   "source": [
    "pol, val = model(np.array([encoded_state]))\n",
    "pol, val = np.array(pol)[0], np.array(val)[0, 0]\n",
    "print(pol)\n",
    "print(val)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[0. 0. 0.]\n",
      "  [0. 0. 0.]]\n",
      "\n",
      " [[0. 0. 0.]\n",
      "  [0. 0. 0.]]]\n"
     ]
    }
   ],
   "source": [
    "a = np.zeros((2, 2))\n",
    "b = np.zeros((2, 2))\n",
    "c = np.zeros((2, 2))\n",
    "x = np.stack([a, b, c], axis=2)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReplayBuffer:\n",
    "    def __init__(self, states = []):\n",
    "        self.states = states\n",
    "\n",
    "    def add(self, state):\n",
    "        self.states.append(state)\n",
    "    \n",
    "    def retrieve_all(self):\n",
    "        X, Y_p, Y_v = zip(*self.states)\n",
    "        X, Y_p, Y_v = np.array(X), np.array(Y_p), np.array(Y_v)\n",
    "        return X, Y_p, Y_v\n",
    "    \n",
    "    def retrieve_last(self, last_count):\n",
    "        n = len(self.states)\n",
    "        start = n - last_count\n",
    "        start = np.clip(start, 0, n-1)\n",
    "        \n",
    "        states = self.states[start: n]\n",
    "\n",
    "        X, Y_p, Y_v = zip(*states)\n",
    "        X, Y_p, Y_v = np.array(X), np.array(Y_p), np.array(Y_v)\n",
    "        return X, Y_p, Y_v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from tensorflow.keras.models import load_model\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "ename": "OSError",
     "evalue": "No file or directory found at models_initial/model50_.h5",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[77], line 15\u001b[0m\n\u001b[0;32m     12\u001b[0m LAST_COUNT \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1500\u001b[39m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m LOAD_MODEL:\n\u001b[1;32m---> 15\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43mload_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMODEL_PATH\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m LOAD_BUFFER:\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(BUFFER_PATH, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n",
      "File \u001b[1;32mc:\\Users\\pauli\\anaconda3\\envs\\dl\\lib\\site-packages\\keras\\utils\\traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m     68\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     72\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[1;32mc:\\Users\\pauli\\anaconda3\\envs\\dl\\lib\\site-packages\\keras\\saving\\save.py:226\u001b[0m, in \u001b[0;36mload_model\u001b[1;34m(filepath, custom_objects, compile, options)\u001b[0m\n\u001b[0;32m    224\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(filepath_str, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    225\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39mexists(filepath_str):\n\u001b[1;32m--> 226\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mIOError\u001b[39;00m(\n\u001b[0;32m    227\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mNo file or directory found at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfilepath_str\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    228\u001b[0m         )\n\u001b[0;32m    230\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mgfile\u001b[38;5;241m.\u001b[39misdir(filepath_str):\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m saved_model_load\u001b[38;5;241m.\u001b[39mload(\n\u001b[0;32m    232\u001b[0m             filepath_str, \u001b[38;5;28mcompile\u001b[39m, options\n\u001b[0;32m    233\u001b[0m         )\n",
      "\u001b[1;31mOSError\u001b[0m: No file or directory found at models_initial/model50_.h5"
     ]
    }
   ],
   "source": [
    "# ITERATION_COUNT = 100\n",
    "START_ITERATION = 0\n",
    "END_ITERATION = 5\n",
    "ITERATIONS = range(START_ITERATION, END_ITERATION)\n",
    "GAMES_PER_ITERATION = 10\n",
    "EPOCH_COUNT = 100\n",
    "BATCH_SIZE = 250\n",
    "LOAD_MODEL = True\n",
    "MODEL_PATH = \"models_initial/model_50.h5\"\n",
    "LOAD_BUFFER = True\n",
    "BUFFER_PATH = \"buffer.pkl\"\n",
    "LAST_COUNT = 1500\n",
    "\n",
    "if LOAD_MODEL:\n",
    "    model = load_model(MODEL_PATH)\n",
    "\n",
    "if LOAD_BUFFER:\n",
    "    with open(BUFFER_PATH, 'rb') as f:\n",
    "        buffer = pickle.load(f)\n",
    "else:\n",
    "    buffer = ReplayBuffer()\n",
    "\n",
    "mcts = MCTS(model, 1, 4)\n",
    "buffer = ReplayBuffer()\n",
    "buffer.states = []\n",
    "\n",
    "for iteration in ITERATIONS:\n",
    "    print(f\"iteration: {iteration + 1}\")\n",
    "\n",
    "    for game in range(GAMES_PER_ITERATION):\n",
    "        print(f\"game: {game + 1}\")\n",
    "        board = gamerules.Board()\n",
    "        boards = []\n",
    "        states = []\n",
    "        p_vals = []\n",
    "        turn = 1\n",
    "\n",
    "        while len(board.getPossibleActions()) > 0:\n",
    "            p = mcts.think(board, turn)\n",
    "            p_vals.append(p)\n",
    "            action = np.random.choice(7, p=p)\n",
    "            \n",
    "            state = board.prepareBoardForPlayer(turn)\n",
    "            state = encode_state(state)\n",
    "            states.append(state)\n",
    "            boards.append(copy.deepcopy(board))\n",
    "\n",
    "            board.updateBoard(action, turn)\n",
    "            \n",
    "            gameWon = board.checkVictory(action, turn)\n",
    "            if gameWon:\n",
    "                break\n",
    "            turn *= -1\n",
    "\n",
    "        res = turn if gameWon else 0\n",
    "        turn = 1\n",
    "        for i in range(len(states)):\n",
    "            state = states[i]\n",
    "            p = p_vals[i]\n",
    "            v = turn * res\n",
    "            turn *= -1\n",
    "\n",
    "            buffer.add((state, p, v))\n",
    "    X, Y_p, Y_v = buffer.retrieve_last(LAST_COUNT)\n",
    "    history = model.fit(\n",
    "        X, {\"policy\": Y_p, \"value\": Y_v},\n",
    "        epochs=EPOCH_COUNT,\n",
    "        batch_size=BATCH_SIZE\n",
    "    )\n",
    "    model.save(f\"models/model_{iteration+1}.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game pair 0, result: (1; 1)\n",
      "game pair 1, result: (-1; 1)\n",
      "game pair 2, result: (0; 1)\n",
      "game pair 3, result: (-1; 1)\n",
      "game pair 4, result: (0; 1)\n",
      "p1_wins: 1: (1; 0)\n",
      "p2_wins: 7: (5; 2)\n",
      "draws: 2\n"
     ]
    }
   ],
   "source": [
    "from utils import test_games\n",
    "\n",
    "# model0 = load_model(\"models_prob_bad/model_init.h5\")\n",
    "model1 = load_model(\"models/model_50.h5\")\n",
    "\n",
    "# mcts0 = MCTS(model0, 2, 1, \"time\")\n",
    "mcts1 = MCTS(model1, 2, 4, \"time\")\n",
    "\n",
    "# p1 = MCTSPlayer(\"Initial model\", mcts0)\n",
    "p1 = RNGPlayer()\n",
    "p2 = MCTSPlayer(\"After iteration model\", mcts1)\n",
    "\n",
    "test_games(p1, p2, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15113\n"
     ]
    }
   ],
   "source": [
    "print(len(buffer.states))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open(\"buffer.pkl\", \"wb\") as f:\n",
    "    pickle.dump(buffer, f)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
